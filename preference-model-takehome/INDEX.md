# Preference Model Take-Home Assignment
## RL Task: Variance-Stabilized Dropout Implementation

---

## ğŸ“‹ Start Here

**New to this submission?** â†’ Read `QUICKSTART.md` (2 min)  
**Want quick overview?** â†’ Read `SUBMISSION_SUMMARY.md` (5 min)  
**Need full details?** â†’ Read `README.md` (15 min)

**To run the task:**
```bash
pip install numpy
python variance_dropout_task.py
```

---

## ğŸ“ Files Guide

### Essential Files
- **variance_dropout_task.py** - Complete task implementation (the actual submission)
- **README.md** - Full documentation with rationale and design decisions
- **requirements.txt** - Dependencies (numpy only)

### Supporting Documentation
- **QUICKSTART.md** - How to run and integrate (5 min read)
- **SUBMISSION_SUMMARY.md** - One-page overview (3 min read)
- **CHECKLIST.md** - Verification against requirements
- **SUBMISSION_MESSAGE.md** - Email template for submission
- **DEMO_SCRIPT.md** - Presentation guide if doing live demo
- **INDEX.md** - This file

---

## ğŸ¯ What This Is

An RL training task where language models learn to:
1. Understand a research paper concept (variance-stabilized dropout)
2. Debug a subtle mathematical error in the implementation
3. Validate the fix with statistical tests

**The bug:** Using `1/(1-p)` scaling instead of `1/âˆš(1-p)`  
**The challenge:** Models must derive the correct formula  
**The validation:** Empirical variance tests (must preserve variance within 10%)

---

## âœ… Key Features

- âœ… **Scientific concept** - Neural network training stability
- âœ… **10-40% difficulty** - Subtle bug, requires math understanding
- âœ… **Clear grading** - Automated statistical tests
- âœ… **Educational value** - Teaches paper â†’ code implementation
- âœ… **Production ready** - Fully documented, tested, calibrated

---

## ğŸ“Š Quick Stats

- **Time spent:** ~4 hours
- **Code:** ~300 lines (including tests, grader, docs)
- **Dependencies:** numpy only
- **Difficulty:** Calibrated for 10-40% pass rate
- **Task type:** Debugging + mathematical reasoning

---

## ğŸš€ For Reviewers

### 5-Minute Review
1. Read `SUBMISSION_SUMMARY.md`
2. Run `python variance_dropout_task.py`
3. Watch buggy fail (43% error) â†’ correct pass (0.1% error)

### 15-Minute Review
1. Read `README.md` sections on difficulty calibration
2. Review task prompt in code
3. Check grading logic
4. Verify against `CHECKLIST.md`

### Integration
- See `QUICKSTART.md` for code examples
- Task is self-contained in single file
- Easy to adapt for different model APIs

---

## ğŸ“§ Submission

**Method 1: Email**
- To: ai@xor.ai
- Use template in `SUBMISSION_MESSAGE.md`
- Attach all files or link to folder

**Method 2: HackerRank**
- URL: https://hr.gs/pm-takehome-x
- Upload all files
- Main: variance_dropout_task.py
- Message Aida when done

**Method 3: Telegram**
- Contact: @ai_aida11
- Send files + brief message

---

## ğŸ¬ Optional: Demo

If presenting live, use `DEMO_SCRIPT.md` for talking points.

---

## â“ Questions?

Check:
- Technical details â†’ `README.md`
- Quick answers â†’ `SUBMISSION_SUMMARY.md`
- Integration â†’ `QUICKSTART.md`
- Requirements â†’ `CHECKLIST.md`

Or contact: ai@xor.ai

---

## ğŸ† Why This Task Excels

| Requirement | How Met | Evidence |
|-------------|---------|----------|
| Scientific concept | Variance stabilization | Math in prompt, real technique |
| Tool usage | Code + stats | Numpy, test execution |
| Clear grading | Automated | Binary pass/fail, 10% tolerance |
| Right difficulty | 10-40% | Subtle bug, needs derivation |
| Teaches value | Paperâ†’code | Core ML skill |

---

**Ready to submit!** ğŸš€

All requirements met. Task is production-ready for RL training.
